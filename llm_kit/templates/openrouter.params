# ===== ОСНОВНЫЕ НАСТРОЙКИ LLM =====

url = https://openrouter.ai/api/v1/chat/completions         # API-эндпоинт сервиса
api_key = укажите_ваш_секретный_api_ключ                    # Ваш секретный API-ключ с OpenRouter
model = укажите_название_модели                             # Название модели (например: deepseek/deepseek-r1:free)

# ===== ДОПОЛНИТЕЛЬНЫЕ ПАРАМЕТРЫ =====

seed = 42                                                   # Установка seed для воспроизводимости генерации ответа
temperature = 0.7                                           # Температура (0.0-2.0): ниже — строже и предсказуемее, выше — больше креатива и разнообразия
max_tokens = 1000                                           # Максимальное количество токенов в ответе

# ===== РЕКОМЕНДУЕМЫЕ (ОПЦИОНАЛЬНЫЕ) ПАРАМЕТРЫ =====

# top_p = 1.0                                               # Параметр ядерной выборки (0.0-1.0): учитывает только топ токены с суммарной вероятностью P
# top_k = 0                                                 # Ограничение выбора топ-K токенов: 0 отключает ограничение, 1 = самый вероятный токен
# frequency_penalty = 0.0                                   # Частотный штраф (-2.0-2.0): снижает повторения пропорционально частоте появления
# presence_penalty = 0.0                                    # Штраф за присутствие (-2.0-2.0): снижает повторение уже встречавшихся токенов
# repetition_penalty = 1.0                                  # Штраф за повторения (0.0-2.0): альтернативный метод контроля повторений
# min_p = 0.0                                               # Минимальная относительная вероятность (0.0-1.0): фильтрует токены относительно наиболее вероятного
# top_a = 0.0                                               # Адаптивная топ-выборка (0.0-1.0): динамический фильтр на основе максимальной вероятности
# stop = []                                                 # Массив стоп-слов: генерация остановится при встрече любого из указанных токенов
# logprobs = false                                          # Возврат логарифмических вероятностей: true включает вероятности выходных токенов
# top_logprobs = 0                                          # Количество топ логвероятностей (0-20): сколько наиболее вероятных токенов показать
# logit_bias = {}                                           # Словарь смещений токенов: изменяет вероятности конкретных токенов (ID: смещение от -100 до 100)
# response_format = {"type": "text"}                        # Формат ответа: {"type": "json_object"} для принудительного JSON
# structured_outputs = false                                # Структурированные выходы: поддержка JSON Schema для форматирования ответов
# tools = []                                                # Массив инструментов: описания функций, которые может вызывать модель
# tool_choice = "auto"                                      # Выбор инструментов: "auto", "none", "required" или конкретный инструмент
# parallel_tool_calls = true                                # Параллельные вызовы функций: true разрешает одновременный вызов нескольких функций

# ===== РЕДКИЕ/СПЕЦИАЛЬНЫЕ ПАРАМЕТРЫ OpenRouter =====

# transforms = ["middle-out"]                               # Трансформации промпта: ["middle-out"] сжимает длинные промпты, [] отключает
# models = []                                               # Альтернативные модели: список моделей для автоматического переключения при недоступности основной
# route = "fallback"                                        # Стратегия маршрутизации: "fallback" для резервных моделей
# provider = {"order": [], "allow_fallbacks": true}         # Настройки провайдера: контроль выбора поставщика модели
# provider.order = []                                       # Порядок провайдеров: список имен провайдеров в порядке приоритета (например: ["Anthropic", "OpenAI"])
# provider.allow_fallbacks = true                           # Разрешить резервные провайдеры: переключение на другого провайдера при недоступности основного
# provider.require_parameters = false                       # Требовать поддержку параметров: использовать только провайдеров, поддерживающих все параметры запроса
# provider.data_collection = "allow"                        # Политика сбора данных: "allow", "deny" - контроль использования данных провайдерами для обучения
# provider.ignore = []                                      # Игнорировать провайдеров: список имен провайдеров, которых следует избегать
# provider.quantizations = []                               # Уровни квантизации: фильтр по уровням сжатия модели (например: ["int4", "int8"])
# provider.sort = "price"                                   # Сортировка провайдеров: "price" по цене, "throughput" по пропускной способности
# include_reasoning = false                                 # Включить рассуждения: для моделей с поддержкой reasoning (например, DeepSeek R1)
# safe_prompt = true                                        # Безопасный промпт: применение фильтров безопасности (специфично для некоторых провайдеров)
# raw_mode = false                                          # Сырой режим: отключение обработки промпта провайдером (специфично для некоторых провайдеров)
# nitro = false                                             # Nitro ускорение: использование оптимизированных провайдеров для повышения скорости
# floor = false                                             # Минимальная цена: использование только самых дешевых провайдеров
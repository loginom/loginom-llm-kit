# ===== ОСНОВНЫЕ НАСТРОЙКИ LLM =====

url = http://localhost:11434/api/chat                   # API-эндпоинт сервиса. Вы можете указать адрес сервера вместо localhost
model = gpt-oss:latest                                        # Название модели (например: llama3.3)

# ===== ДОПОЛНИТЕЛЬНЫЕ ПАРАМЕТРЫ =====

# seed = 42                                               # Установка seed для воспроизводимости генерации ответа
# temperature = 0.5                                       # Температура (0.0-2.0): ниже — строже и предсказуемее, выше — больше креатива и разнообразия
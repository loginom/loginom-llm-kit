# ===== ОСНОВНЫЕ НАСТРОЙКИ LLM =====

url = https://gigachat.devices.sberbank.ru/api/v1/chat/completions  # API-эндпоинт сервиса
api_key = укажите_ваш_секретный_ключ_авторизации                    # Ваш секретный Authorization Key для GigaChat
model = GigaChat                                     # Название модели (например: GigaChat-Pro)

# ===== ДОПОЛНИТЕЛЬНЫЕ ПАРАМЕТРЫ =====

temperature = 0.7                                                   # Температура (0.0-2.0): ниже — строже и предсказуемее, выше — больше креатива и разнообразия
max_tokens = 1000                                                   # Максимальное количество токенов в ответе

# ===== РЕКОМЕНДУЕМЫЕ (ОПЦИОНАЛЬНЫЕ) ПАРАМЕТРЫ =====

# top_p = 1.0                                                       # Параметр ядерной выборки (0.0-1.0): учитывает только топ токены с суммарной вероятностью P
# repetition_penalty = 1.1                                          # Штраф за повторения (0.0-2.0): чем выше, тем меньше повторений, но может влиять на связность
# function_call = auto                                              # Управление вызовом функций: auto, none или объект с именем функции
# functions = []                                                    # Массив описаний пользовательских функций для вызова моделью
# profanity_check = true                                            # Проверка на нецензурную лексику: true включает фильтр, false отключает
# system = ""                                                       # Системное сообщение для настройки поведения модели
# stop = []                                                         # Массив стоп-слов: генерация прекратится при встрече любого из этих токенов
# user = ""                                                         # Идентификатор пользователя для персонализации и аналитики
# update_interval = 1.0                                             # Минимальный интервал в секундах между отправкой токенов при стриминге

# ===== РЕДКИЕ/СПЕЦИАЛЬНЫЕ ПАРАМЕТРЫ GigaChat =====

# timeout = 30.0                                                    # Таймаут запроса в секундах: максимальное время ожидания ответа от API
# n = 1                                                             # Количество вариантов ответа: сколько альтернативных ответов сгенерировать
# presence_penalty = 0.0                                            # Штраф за присутствие токенов (-2.0-2.0): снижает вероятность повторения уже встречавшихся слов
# frequency_penalty = 0.0                                           # Частотный штраф (-2.0-2.0): штрафует токены пропорционально частоте их появления
# logit_bias = {}                                                   # Словарь смещений логитов: позволяет увеличить/уменьшить вероятность конкретных токенов
# echo = false                                                      # Включение входных токенов в ответ: true возвращает исходный запрос вместе с ответом
# best_of = 1                                                       # Количество кандидатов для выбора лучшего: модель сгенерирует N вариантов и вернет лучший
# suffix = ""                                                       # Суффикс после ответа модели: текст, который добавится в конец генерации
# logprobs = null                                                   # Количество вероятностей токенов для возврата: null отключает, число включает N наиболее вероятных
# context_length_exceeded = truncate                                # Поведение при превышении контекста: truncate обрезает, error возвращает ошибку